\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage[usenames,dvipsnames]{color}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{booktabs,footmisc}
\usepackage{hyperref}
\usepackage[all]{hypcap}

\usepackage{topcapt}
\usepackage[T1]{fontenc}


 
% include the lines below to use a nicer fixed-width font than the default one
 
\lstset{fancyvrb=true}
\lstset{
	basicstyle=\small\tt,
	identifierstyle=,
	commentstyle=\color{Bittersweet},
	stringstyle=\color{red},
	showstringspaces=false,
	tabsize=3,
	%numbers=left,
	captionpos=b,
	%xleftmargin=2em
%	numberstyle=\tiny
	%stepnumber=4
	}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Repast Simphony Batch Runs Using Hadoop}
\author{Michael Henry and Don Bennett - Mitre, Nick Collier - Repast Development Team}
%\date{\today}                                           % Activate to display a given date or no date

\begin{document} 
\maketitle
\setcounter{section}{-1}

\section{Before we Get Started}
Before we can do anything with Repast Simphony, we need to make sure that we have a proper installation of Repast Simphony. Instructions on downloading and installing Repast Simphony on various platforms can be found on the \href{http://repast.sourceforge.net/download.html}{Repast website}.\footnote{http://repast.sourceforge.net/download.html} Repast Simphony 2.3 requires at least Java 7, but will run on Java 8 as well. Java 7 / 8  can be found at the \href{http://www.oracle.com/technetwork/java/javase/downloads/index.html}{Java Standard Edition Downloads Page}.\footnote{http://www.oracle.com/technetwork/java/javase/downloads/index.html} 

This document assumes working knowledge of the Repast Simphony batch run mechanism as well as knowledge of Hadoop. More info on the batch run mechanism can be found in the \href{http://repast.sourceforge.net/docs/RepastBatchRunsGettingStarted.pdf}{Repast Batch Run Getting Started Guide}.\footnote{http://repast.sourceforge.net/docs/RepastBatchRunsGettingStarted.pdf} More information on Hadoop can be found at the \href{https://hadoop.apache.org}{Hadoop Website}.\footnote{http://https://hadoop.apache.org} The example code and the documentation on which this documents is based were contributed to Repast Simphony by Mitre under a BSD style license and we thank them for their contribution. The project was developed by the MITRE Corporation under FAA Mission-Oriented Investigation and Experimentation.

\section{Repast Simphony Batch Runs Using Hadoop}
The purpose of this document is to explain how to enable Repast Simphony simulations to run on a Hadoop cluster as a map / reduce job. The simulations themselves are run as mappers and the output produced by each simulation is passed to the reduce via a write on a Hadoop Context. The companion code to this document is an example of the Java Zombies model adapted to work with Hadoop. That Repast Simphony project should be contained in the zip file that accompanies this document. The example source is divided into two packages: zombies and hadoop. The zombies package includes the model as well as any model specific hadoop code (e.g. the JZombies specific Hadoop reducer). The hadoop package includes code that can be used for any model and adapts the archive created by Repast Simphony batch for use with Hadoop.

The process of configuring a Repast Simphony model to run on Hadoop is two-fold:
\begin{enumerate}
\item 
Adapting your model to work with Hadoop by converting data output to key value pairs and writing a Hadoop Reducer to process that data in some appropriate way.
\item
Adapting the archive produced by Repast Simphony's batch run mechanism to work with Hadoop.
\end{enumerate}

\subsection{Adapting Your Model to Work with Hadoop}
The first step to performing batch runs on Hadoop is to adapt your code to work with Hadoop.
\begin{enumerate}
\item
Create a custom  \texttt{DataSink}  and register it with Repast's Data Set recording mechanism. This \texttt{DataSink} will transform your output into key / value pairs and pass those to Hadoop. You register a  \texttt{DataSink} using a \texttt{ModelInitializer}. The \texttt{HadoopDataSink} in the companion code is an example of such a \texttt{ModelInitilializer}. The \texttt{ModelInitializer} must also be specified in the scenario.xml in your model's scenario folder in order for it to be run when the scenario is loaded. See Listing ~\ref{lst:scenario} for an example from the Java Zombies scenario.

\noindent\begin{minipage}[h]{\textwidth}
\vspace{.2in}
\lstset{language=xml,caption=Specifying the ModelInitializer in scenario.xml,label=lst:scenario}
\begin{lstlisting}
<Scenario>
...
<model.initializer class="hadoop.HadoopDataSink" />
</Scenario>
\end{lstlisting}
\vspace{.2in}
\end{minipage}

A \texttt{ModelInitilializer} runs when a scenario is loaded. Its initialize method typically adds a controller action to the scenario that will be executed whenever a run or batch is initialized. When a DataSink is to be added, this is done in the batchInitialize method. See Listing \ref{lst:batchInit}. The \texttt{DataSink} itself is added by finding by name the DataSetBuilder for the data set that will produce the data you want to send to the reduce. You then add a \texttt{DataSink} implementation to that builder. The example  \texttt{DataSink} in  \texttt{HadoopDataSink} example code should work for any project. There, the data added via the append method method is appended to a StringBuilder as key / value pairs. The key and value are delimited by `:' and each pair by a `,'. The collect method takes the String produced by the StringBuilder, extracts the ``run'' key / value pair and writes a new key value to Hadoop where the key is the run number and the value is all the key value pairs (see Listing \ref{lst:datasink}).

\noindent\begin{minipage}[h]{\textwidth}
\vspace{.2in}
\lstset{language=java,caption=Adding the Controller Action with a ModelInitializer,label=lst:batchInit}
\begin{lstlisting}
@Override
public void initialize(Scenario scenario, RunEnvironmentBuilder builder) {
scenario.addMasterControllerAction(new NullAbstractControllerAction() {
	@Override
	public void batchInitialize(RunState runState, Object contextId) {
		DataSetRegistry registry = 
			(DataSetRegistry)runState.
			getFromRegistry(DataConstants.REGISTRY_KEY);
		DataSetManager manager = registry.getDataSetManager(contextId);
		DataSetBuilder<?> builder = manager.getDataSetBuilder("Agent Counts");
		
		builder.addDataSink(new DataSink() {
			...
\end{lstlisting}
\vspace{.2in}
\end{minipage}

\noindent\begin{minipage}[h]{\textwidth}
\vspace{.2in}
\lstset{language=java,caption=Collecting the Data with a Custom DataSink,label=lst:datasink}
\begin{lstlisting}
	new DataSink() {
					
		private Context collector = COLLECTOR;
		private StringBuilder entry;
							
		@Override
		public void rowStarted() {
			if(entry == null){
				entry = new StringBuilder();
			}else{
				collect(entry.toString());
				entry = new StringBuilder();
			}
		}
		
		@Override
		public void rowEnded() {
			entry.replace(entry.length() - 1, entry.length(), "");
			
		}
		...
		
		@Override
		public void append(String key, Object value) {
			entry.append(key + ":" + value + ",");
		}
		
		// collects run number -> output
		@SuppressWarnings("unchecked")
		private void collect(String key){
			String[] fields = key.split("\\,");
			for(String field : fields){
				if(field.startsWith("run")){
					int run = (int) Double.parseDouble(field.split("\\:")[1]);
					try {
						collector.write(new Text(run + ""), new Text(key));
					} catch (Exception e) {
						e.printStackTrace();
					}
				}
			}
		}
	}

\end{lstlisting}
\vspace{.2in}
\end{minipage}

\item
The next step is to add a Reducer class that extends Hadoop's Reducer<Text, Text, Text, Text>. This class will be responsible for recording all output from the simulation from the fields collected in the DataSink. An example is provided for the JZombies project in \texttt{HadoopZombies}. Exactly what happens in the reducer will be model dependent, but it will typically iterate over the values passed from the DataSink, splitting them into their constituent key value pairs and do something with those key value pairs. In the example case, the reducer iterates through all the key values pairs to determine the last tick in which a Human was alive and writes out that value.

\item
The final step is to create a class with main method that calls \texttt{MapReduceJob.run()}, passing that the number of mappers to use (or 0 for automatic config), the name of the job on the cluster and the name of the reducer class. In the JZombies example, the main method is in \texttt{HadoopZombies} where the reducer is also defined but it need not be. The \texttt{MapReduceJob} class is part of the hadoop package in the example code and performs the typical Hadoop job configuration as well as providing a Mapper that will run Repast Simphony simulations in batch mode.
\end{enumerate}


\subsection{Adapting Repast Simphony's Batch Archive to Work with Hadoop}
Once you've modified your code to work with Hadoop as described in the steps above, you need to adapt the jar archive created by Repast Simphony's batch run mechanism so that it can perform the batch runs as mappers on the Hadoop cluster.

\begin{enumerate}
\item
Generate the complete\_model.jar etc. and as described in the Repast Batch Run Getting Started Guide.
\item
Run \texttt{HadoopUtils.makeHadoopJar}, passing it the main class from step 3 in the previous section, the path to the complete\_model.jar from step 1 of this section and the path of a jar file that will be created. This new jar file can then be used to perform the actual model runs on a Hadoop cluster. The \texttt{HadoopUtils} class is in the hadoop package in the sample code.
\end{enumerate}

\subsection{Running the Hadoop Job}
\begin{enumerate}
\item Transfer the jar created in step 2 of the previous section to a machine that has access to the hadoop commands (e.g. hadoop -fs etc.)
\item Run this jar as a normal java processes (i.e. java -jar MyHadoopJar.jar)
\item After the process completes, there will be a folder named ``output'' within the jar that was executed. This folder will contain the Repast Simulation output from the data sinks.
\end {enumerate}


\end{document}  